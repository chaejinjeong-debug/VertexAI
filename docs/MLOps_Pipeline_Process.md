# VertexAI Pipeline í”„ë¡œì„¸ìŠ¤ ë¬¸ì„œ

## 1. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜

### ê°œìš”
Customer Churn ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ End-to-End ML íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.
ì»¨í…Œì´ë„ˆ ê¸°ë°˜ ì»´í¬ë„ŒíŠ¸ë¡œ êµ¬ì„±ë˜ì–´ Vertex AI Pipelinesì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.

### ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨

```mermaid
flowchart TB
    subgraph Input["ğŸ“¥ Input"]
        BQ[(BigQuery<br/>train_dataset)]
    end

    subgraph Pipeline["ğŸ”„ Vertex AI Pipeline"]
        DL["ğŸ“Š Data Load<br/>Component"]
        TR["ğŸ¤– Train<br/>Component"]
        EV1["ğŸ“ˆ Eval Valid<br/>Component"]
        EV2["ğŸ“ˆ Eval Test<br/>Component"]
    end

    subgraph Artifacts["ğŸ“¦ Artifacts"]
        DS[("train.parquet<br/>valid.parquet<br/>test.parquet")]
        MODEL[("model.pkl<br/>model_meta.json")]
        METRICS[("metrics.json")]
    end

    BQ --> DL
    DL --> DS
    DS --> TR
    TR --> MODEL
    MODEL --> EV1
    MODEL --> EV2
    DS --> EV1
    DS --> EV2
    EV1 --> METRICS
    EV2 --> METRICS
```

---

## 2. ì»´í¬ë„ŒíŠ¸ ìƒì„¸

### 2.1 Data Load Component

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì´ë¯¸ì§€** | `asia-northeast3-docker.pkg.dev/{PROJECT}/vertex-ai-pipelines/component-data_load:latest` |
| **ì…ë ¥** | BigQuery í…Œì´ë¸” ê²½ë¡œ, ë¼ë²¨ ì»¬ëŸ¼, ì‹œê°„ ì»¬ëŸ¼, split ë¹„ìœ¨ |
| **ì¶œë ¥** | `train.parquet`, `valid.parquet`, `test.parquet` |
| **ê¸°ëŠ¥** | BigQueryì—ì„œ ë°ì´í„° ë¡œë“œ í›„ ì‹œê°„ ê¸°ì¤€ train/valid/test ë¶„í•  |

**íŒŒë¼ë¯¸í„°:**
- `input_bq_table`: BigQuery í…Œì´ë¸” ê²½ë¡œ (ì˜ˆ: `project.dataset.table`)
- `label_column`: ë¼ë²¨ ì»¬ëŸ¼ëª… (ì˜ˆ: `label_churn_60d`)
- `time_column`: ì‹œê°„ ê¸°ì¤€ ë¶„í•  ì»¬ëŸ¼ (ì˜ˆ: `label_timestamp`)
- `train_ratio`: í•™ìŠµ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸: 0.7)
- `valid_ratio`: ê²€ì¦ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸: 0.15)

### 2.2 Train Component

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì´ë¯¸ì§€** | `asia-northeast3-docker.pkg.dev/{PROJECT}/vertex-ai-pipelines/component-train:latest` |
| **ì…ë ¥** | Dataset artifacts, Feature ì»¬ëŸ¼ ëª©ë¡, ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° |
| **ì¶œë ¥** | `model.pkl`, `model_meta.json` |
| **ê¸°ëŠ¥** | ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ (RandomForest / LogisticRegression) |

**íŒŒë¼ë¯¸í„°:**
- `feature_columns`: í”¼ì²˜ ì»¬ëŸ¼ ëª©ë¡ (ì½¤ë§ˆ êµ¬ë¶„)
- `label_column`: ë¼ë²¨ ì»¬ëŸ¼ëª…
- `model_type`: ëª¨ë¸ ìœ í˜• (`random_forest` / `logistic_regression`)
- `n_estimators`: íŠ¸ë¦¬ ê°œìˆ˜ (RandomForest, ê¸°ë³¸: 100)
- `max_depth`: ìµœëŒ€ ê¹Šì´ (ê¸°ë³¸: 10)
- `random_state`: ëœë¤ ì‹œë“œ (ê¸°ë³¸: 42)

**ì‚¬ìš© í”¼ì²˜:**
```
orders_30d, orders_90d, revenue_30d, revenue_90d,
avg_order_value_90d, distinct_products_90d,
distinct_categories_90d, days_since_last_order
```

### 2.3 Eval Component

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì´ë¯¸ì§€** | `asia-northeast3-docker.pkg.dev/{PROJECT}/vertex-ai-pipelines/component-eval:latest` |
| **ì…ë ¥** | Model artifact, Dataset artifact, í‰ê°€ ëŒ€ìƒ split |
| **ì¶œë ¥** | `metrics.json` |
| **ê¸°ëŠ¥** | ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ (ROC-AUC, PR-AUC, Accuracy, Positive Rate) |

**íŒŒë¼ë¯¸í„°:**
- `eval_split`: í‰ê°€ ëŒ€ìƒ (`valid` / `test`)

**ì¶œë ¥ ë©”íŠ¸ë¦­:**
- `roc_auc`: ROC-AUC ì ìˆ˜
- `pr_auc`: PR-AUC ì ìˆ˜
- `accuracy`: ì •í™•ë„
- `positive_rate`: ì–‘ì„± ë¹„ìœ¨

---

## 3. ì‹¤í–‰ ì›Œí¬í”Œë¡œìš°

### Sequence Diagram

```mermaid
sequenceDiagram
    participant Dev as ğŸ‘¨â€ğŸ’» Developer
    participant AR as ğŸ“¦ Artifact Registry
    participant VAI as â˜ï¸ Vertex AI Pipelines
    participant BQ as ğŸ—„ï¸ BigQuery

    Note over Dev: 1. íŒŒì´í”„ë¼ì¸ ì»´íŒŒì¼
    Dev->>Dev: python -m src.pipelines.compile

    Note over Dev,AR: 2. ì»´í¬ë„ŒíŠ¸ ì´ë¯¸ì§€ ë¹Œë“œ/í‘¸ì‹œ
    Dev->>AR: ./scripts/build_push.sh data_load
    Dev->>AR: ./scripts/build_push.sh train
    Dev->>AR: ./scripts/build_push.sh eval

    Note over Dev,VAI: 3. íŒŒì´í”„ë¼ì¸ ì œì¶œ
    Dev->>VAI: python -m src.pipelines.run

    Note over VAI,BQ: 4. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    VAI->>BQ: Data Load (Query & Split)
    VAI->>VAI: Train (Model Training)
    VAI->>VAI: Eval Valid (Validation)
    VAI->>VAI: Eval Test (Test)

    Note over Dev,VAI: 5. ëª¨ë‹ˆí„°ë§
    Dev->>VAI: python -m src.pipelines.monitor --latest
```

### ì‹¤í–‰ ëª…ë ¹ì–´

```bash
# Step 1: íŒŒì´í”„ë¼ì¸ ì»´íŒŒì¼
python -m src.pipelines.compile

# Step 2: ì»´í¬ë„ŒíŠ¸ ì´ë¯¸ì§€ ë¹Œë“œ ë° í‘¸ì‹œ
./scripts/build_push.sh data_load
./scripts/build_push.sh train
./scripts/build_push.sh eval
# ë˜ëŠ” ì „ì²´ ë¹Œë“œ: ./scripts/build_push_all.sh

# Step 3: íŒŒì´í”„ë¼ì¸ ì œì¶œ
python -m src.pipelines.run

# Step 4: ì‹¤í–‰ ëª¨ë‹ˆí„°ë§
python -m src.pipelines.monitor --latest
```

---

## 4. ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
src/
â”œâ”€â”€ components/                 # íŒŒì´í”„ë¼ì¸ ì»´í¬ë„ŒíŠ¸
â”‚   â”œâ”€â”€ _template/              # ì»´í¬ë„ŒíŠ¸ í…œí”Œë¦¿
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ src/main.py
â”‚   â”œâ”€â”€ data_load/              # ë°ì´í„° ë¡œë“œ ì»´í¬ë„ŒíŠ¸
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ src/main.py
â”‚   â”œâ”€â”€ train/                  # í•™ìŠµ ì»´í¬ë„ŒíŠ¸
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ src/main.py
â”‚   â””â”€â”€ eval/                   # í‰ê°€ ì»´í¬ë„ŒíŠ¸
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â””â”€â”€ src/main.py
â””â”€â”€ pipelines/                  # íŒŒì´í”„ë¼ì¸ ì •ì˜
    â”œâ”€â”€ pipeline.py             # íŒŒì´í”„ë¼ì¸ ì •ì˜ (KFP)
    â”œâ”€â”€ compile.py              # JSON ì»´íŒŒì¼ëŸ¬
    â”œâ”€â”€ run.py                  # Vertex AI ì œì¶œ
    â””â”€â”€ monitor.py              # ì‹¤í–‰ ìƒíƒœ ëª¨ë‹ˆí„°ë§

scripts/
â”œâ”€â”€ build_push.sh               # ë‹¨ì¼ ì»´í¬ë„ŒíŠ¸ ë¹Œë“œ/í‘¸ì‹œ
â”œâ”€â”€ build_push_all.sh           # ì „ì²´ ì»´í¬ë„ŒíŠ¸ ë¹Œë“œ/í‘¸ì‹œ
â””â”€â”€ smoke_test.sh               # ë¡œì»¬ ê²€ì¦
```

---

## 5. íŒŒì´í”„ë¼ì¸ íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ì„¤ëª… |
|---------|--------|------|
| `input_bq_table` | `{project}.featurestore_demo.train_dataset` | í•™ìŠµ ë°ì´í„° í…Œì´ë¸” |
| `label_column` | `label_churn_60d` | ë¼ë²¨ ì»¬ëŸ¼ |
| `time_column` | `label_timestamp` | ì‹œê°„ ë¶„í•  ê¸°ì¤€ ì»¬ëŸ¼ |
| `train_ratio` | `0.7` | í•™ìŠµ ë°ì´í„° ë¹„ìœ¨ |
| `valid_ratio` | `0.15` | ê²€ì¦ ë°ì´í„° ë¹„ìœ¨ |
| `model_type` | `random_forest` | ëª¨ë¸ ìœ í˜• |
| `n_estimators` | `100` | íŠ¸ë¦¬ ê°œìˆ˜ |
| `max_depth` | `10` | ìµœëŒ€ íŠ¸ë¦¬ ê¹Šì´ |
| `random_state` | `42` | ëœë¤ ì‹œë“œ |

---

## 6. ëª¨ë‹ˆí„°ë§

### Monitor ëª…ë ¹ì–´

```bash
# ìµœì‹  íŒŒì´í”„ë¼ì¸ ëª¨ë‹ˆí„°ë§
python -m src.pipelines.monitor --latest

# íŠ¹ì • Job ëª¨ë‹ˆí„°ë§
python -m src.pipelines.monitor <job_name>
python -m src.pipelines.monitor customer-churn-training-pipeline-20260130085524

# ì˜µì…˜
--interval 10     # í´ë§ ê°„ê²© (ì´ˆ)
--no-color        # ì»¬ëŸ¬ ì¶œë ¥ ë¹„í™œì„±í™”
```

### ìƒíƒœ í‘œì‹œ

| ìƒíƒœ | ìƒ‰ìƒ | ì„¤ëª… |
|------|------|------|
| `PENDING` | ğŸŸ¡ Yellow | ëŒ€ê¸° ì¤‘ |
| `RUNNING` | ğŸ”µ Cyan | ì‹¤í–‰ ì¤‘ |
| `SUCCEEDED` | ğŸŸ¢ Green | ì„±ê³µ |
| `FAILED` | ğŸ”´ Red | ì‹¤íŒ¨ |
| `CANCELLED` | ğŸŸ£ Magenta | ì·¨ì†Œë¨ |

---

## 7. í™˜ê²½ ì„¤ì •

### í™˜ê²½ ë³€ìˆ˜ (build_push.sh)

| ë³€ìˆ˜ | ê¸°ë³¸ê°’ | ì„¤ëª… |
|------|--------|------|
| `PROJECT_ID` | `heum-alfred-evidence-clf-dev` | GCP í”„ë¡œì íŠ¸ ID |
| `REGION` | `asia-northeast3` | GCP ë¦¬ì „ |
| `REPOSITORY` | `vertex-ai-pipelines` | Artifact Registry ì €ì¥ì†Œ |
| `IMAGE_TAG` | Git SHA | ì´ë¯¸ì§€ íƒœê·¸ |

### ì„¤ì • íŒŒì¼

`configs/env.yaml` íŒŒì¼ì—ì„œ GCP í”„ë¡œì íŠ¸, ë¦¬ì „, BigQuery í…Œì´ë¸” ë“±ì„ ì„¤ì •í•©ë‹ˆë‹¤.

---

## 8. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ì¼ë°˜ì ì¸ ë¬¸ì œ

**1. ì´ë¯¸ì§€ ë¹Œë“œ ì‹¤íŒ¨**
```bash
# Docker ì¸ì¦ í™•ì¸
gcloud auth configure-docker asia-northeast3-docker.pkg.dev
```

**2. íŒŒì´í”„ë¼ì¸ ì œì¶œ ì‹¤íŒ¨**
```bash
# ì»´íŒŒì¼ íŒŒì¼ í™•ì¸
ls src/pipelines/compiled/

# ê¶Œí•œ í™•ì¸
gcloud projects get-iam-policy <PROJECT_ID>
```

**3. ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨**
```bash
# BigQuery í…Œì´ë¸” í™•ì¸
bq show <project>.<dataset>.<table>
```

---

*Last Updated: 2026-01-30*
